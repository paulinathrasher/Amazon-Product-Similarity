{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLfW-QzRRJ2Z"
      },
      "source": [
        "From: Alex Rivera, Head of Product Management\n",
        "Challenge: Our product categorization system currently relies on manual tagging by our content\n",
        "team. This process is time-consuming and inconsistent. We believe that customer reviews contain rich information about product characteristics that could be used to automatically classify\n",
        "products into the correct categories.\n",
        "Request: Develop a classification system that can automatically categorize products into their\n",
        "appropriate departments (electronics, home goods, fashion, beauty, etc.) based solely on the\n",
        "language used in customer reviews. This would help us with:\n",
        "• Automatically categorizing new products\n",
        "• Identifying miscategorized existing products\n",
        "• Understanding cross-category product attributes\n",
        "Success metrics: Classification accuracy of at least 85% across major categories and a clear\n",
        "explanation of which review elements are most predictive of product categories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyw9H6b-n_rk",
        "outputId": "bf756fb2-381a-4f4d-d067-f08c616527f5"
      },
      "outputs": [],
      "source": [
        "from de3_preprocessing import load_preprocessed, compute_tfidf, normalize_features\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alDXbWYeoBDj"
      },
      "outputs": [],
      "source": [
        "df, embeddings = load_preprocessed(\"/content/drive/MyDrive/DEAssignment3/review\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUtSuOztTVU0"
      },
      "source": [
        "TF-IDF Vectorizer is used below to show the top terms used in reviews for each category. This technique weighs how important each word is relative to all reviews. Important words like \"album\", \"fit\", or \"battery\" get higher scores whereas more vague terms get low scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "LNVGdYJKoDVH",
        "outputId": "2995b6d0-01f4-4ed9-97a7-2cccab52c98a"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "### 1. TF-IDF Term Visualization\n",
        "tfidf = TfidfVectorizer(max_features=300) #Converts text into a matrix of word importance scores. 300 most important words are kept\n",
        "tfidf_matrix = tfidf.fit_transform(df[\"clean_text\"])\n",
        "tfidf_features = np.array(tfidf.get_feature_names_out())\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_features)\n",
        "tfidf_df[\"category\"] = df[\"category\"].values\n",
        "\n",
        "top_n = 10 #grabs top 10 terms per category\n",
        "top_terms_all = []\n",
        "for category in tfidf_df[\"category\"].unique():\n",
        "    cat_df = tfidf_df[tfidf_df[\"category\"] == category].drop(columns=\"category\")\n",
        "    avg_scores = cat_df.mean().sort_values(ascending=False).head(top_n) #avgs score\n",
        "    for term, score in avg_scores.items():\n",
        "        top_terms_all.append({\"category\": category, \"term\": term, \"score\": score})\n",
        "\n",
        "top_terms_df = pd.DataFrame(top_terms_all)\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=top_terms_df, x=\"term\", y=\"score\", hue=\"category\")\n",
        "plt.title(\"Top TF-IDF Terms by Category\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGx5C7a2oDlC"
      },
      "source": [
        "Review level classification\n",
        "-Review length and helpfulness votes are normalized (scaled)\n",
        "-Text features (TF-IDF) and semantic features, and numeric features were horizontally stacked. This forms a single feature matrix that can then be used in modeling\n",
        "-Models Used\n",
        "\n",
        "\n",
        "*   Logistic Regression\n",
        "*   Random Forest\n",
        "*   Support Vector Machine\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kukv9ra4oGr-",
        "outputId": "2d84fc4a-3b05-4aa2-acf4-03eecf4c81da"
      },
      "outputs": [],
      "source": [
        "# Normalize numeric features\n",
        "scaled_numeric, numeric_sparse = normalize_features(df, [\"review_length\", \"helpful_vote\"])\n",
        "embedding_sparse = csr_matrix(embeddings)\n",
        "X_combined = hstack([tfidf_matrix, embedding_sparse, numeric_sparse])\n",
        "y = df[\"category\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Logistic Regression\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred_log = logreg.predict(X_test)\n",
        "print(\"Logistic Regression:\\n\", classification_report(y_test, y_pred_log))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_log))\n",
        "print(\"\")\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "print(\"Random Forest:\\n\", classification_report(y_test, y_pred_rf))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
        "print(\"\")\n",
        "\n",
        "# Support Vector Machine\n",
        "svm = LinearSVC(max_iter=1000)\n",
        "svm.fit(X_train, y_train)\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "print(\"Support Vector Machine:\\n\", classification_report(y_test, y_pred_svm))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6nkRxwCoJwT"
      },
      "source": [
        "Product Level Classification\n",
        "- This next approach aggregates information across all reviews for a given product, grouped by parent_asin\n",
        "- For each product, all embeddings are aggregated (averaged) to create a single embedding vector- captures overall sentiment/themes\n",
        "-Each product assigned a category label based on first review found\n",
        "-Models used:\n",
        "\n",
        "\n",
        "*   Logistic Regression\n",
        "*   Random Forest Classifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5lkxIhuoLOG",
        "outputId": "ade125ff-9a98-49e2-c7a9-935af0b62a38"
      },
      "outputs": [],
      "source": [
        "grouped = df.groupby(\"parent_asin\") #products group by parent_asin\n",
        "product_embeddings = {}\n",
        "product_labels = {}\n",
        "for product_id, group in grouped:\n",
        "    product_embeddings[product_id] = np.mean(embeddings[group.index], axis=0)\n",
        "    product_labels[product_id] = group[\"category\"].iloc[0]\n",
        "\n",
        "X_product = np.array(list(product_embeddings.values()))\n",
        "y_product = np.array(list(product_labels.values()))\n",
        "\n",
        "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X_product, y_product, test_size=0.2, stratify=y_product, random_state=42)\n",
        "\n",
        "# Product-Level Logistic Regression\n",
        "clf_p = LogisticRegression(max_iter=1000)\n",
        "clf_p.fit(X_train_p, y_train_p)\n",
        "y_pred_p = clf_p.predict(X_test_p)\n",
        "print(\"Product-Level Logistic Regression:\\n\", classification_report(y_test_p, y_pred_p))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_p, y_pred_p))\n",
        "\n",
        "# Product-Level Random Forest\n",
        "rf_p = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_p.fit(X_train_p, y_train_p)\n",
        "y_pred_rf_p = rf_p.predict(X_test_p)\n",
        "print(\"Product-Level Random Forest:\\n\", classification_report(y_test_p, y_pred_rf_p))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_p, y_pred_rf_p))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
